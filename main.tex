\documentclass[twocolumn,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{CJKutf8}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{indentfirst}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }
\usepackage[a4paper, top = 2.5cm, bottom = 2.5cm, left = 3.17cm, right = 3.17cm]{geometry}
\setlength{\parindent}{12pt}

\title{GA-based Training-Free NAS Algorithm with Hybrid Score Function}
\author{Hsieh Cheng-Han}
\date{2023}

\begin{document}
\begin{CJK*}{UTF8}{bsmi}

\maketitle

\section{Abstract}
    In the last few years, Artificial Neural Network (ANN) has been used in a variety of fields, i.e., image classification\cite{}, speech recognition\cite{}, and Natural Language Processing\cite{}.\par
Most of the architectures of ANN are hand-designed by experts, consuming lots of time and resource. This problem induce the researches of Neural Architecture Search (NAS) algorithm, providing an automated, fast, and accurate approach to build a good architecture of ANN.\par
    However, the NAS algorithm\cite{} in the past is time-consuming, which is caused by the fact that, during the searching, a candidate of architectures must be trained to know how the performance of this architecture. Thus, plenty of training-free NAS algorithm are developed in recent years. By using training-free score function to evaluate an architecture, there's no requirement for training architectures anymore. Compare with training-required NAS algorithm, training-free NAS algorithm tend to be faster and consuming less resource.\par
Neverthesless, the low correlation between single Training-Free Score Function and the performance of an architecture limits the performance of training-free NAS algorithms. To mitigate this problem, we propose a genetic-based training-free NAS algorithm with hybrid training-free score function, which combines three highly heterogeneous training-free score functions to evaluate an architecture. To evaluate the performance of the proposed algorithm, we compared it with several NAS algorithms, including weight-sharing methods, non-weight-sharing methods, and NASWOT. We expect develope a faster and more accurate training-free NAS algorithm.\par

\begin{thebibliography}{9}
\end{thebibliography}


\end{CJK*}
\end{document}
